{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Exploratória da Tabela de Requisição de Materiais\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook apresenta a análise exploratória de dados da tabela de requisição de materiais. o principal intuito desta análise é entender melhor os dados relacionados a materiais e a partir disto gerar hipóteses.\n",
    "\n",
    "Nesse sentido, aqui serão examinadas as principais características de um conjunto de dados, identificando padrões, tendências, outliers e possíveis relações entre variáveis. Utilizando estatísticas descritivas, gráficos e visualizações, a AED ajudará a entender a estrutura dos dados, verificar hipóteses e orientar etapas futuras, como modelagem ou limpeza. Essa análise é essencial para fazer escolhas informadas sobre quais métodos e técnicas aplicar no restante do projeto.\n",
    "\n",
    "O notebook apresenta as seguintes seções:\n",
    "1. Instalações\n",
    "2. Importação da Base\n",
    "3. Início das Análises \n",
    "4. Considerações Finais\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Instalações "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install boto3\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Importação da Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = pd.read_csv('TABELA_BIG_DATA_REQ_MAT_202410111115.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Início das Análises \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao visualizar as primeiras linhas da tabela é possível perceber que muitas colunas apresentam valores nulos como 'NaN', pensando nisso, essas colunas serão analisadas de forma mais aprofundada para entender se realmente uma parte considerável dos seus valores são nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "database.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Comprimento da base: {len(database)}\")\n",
    "\n",
    "for column in database:\n",
    "    print(f\"Qtd. de NaN na coluna '{column}': {database[column].isna().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir da célula acima é possível ver que as colunas: \"TIPOREQMATCOD\", \"ITREQMATOBS\", \"REQMATDATACANC\", \"REQMATUSUCODCANC\", \"MOTCANCCODESTR\", \"ITREQMATCANCDATA\", \"ITREQMATCANCUSUCOD\", \"REQMATTEXTOCANC1\", \"REQMATTEXTOCANC2\", \"REQMATTEXTOCANC3\", \"REQMATTEXTO2\" e \"REQMATTEXTO3\" apresentam todos ou quase todos os valores nulos. Por isso, para realizar esta análise, a princípio, serão removidas todas as colunas que apresentam mais de 100.000 valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_wout_nan = database\n",
    "for column in database_wout_nan:\n",
    "    if database_wout_nan[column].isna().sum() > 100000:\n",
    "        database_wout_nan =  database_wout_nan.drop(column, axis=1)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "print(database_wout_nan.shape)\n",
    "database_wout_nan.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in database_wout_nan:\n",
    "    print(f\" '{column}':  {len(database_wout_nan[column].unique())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No output gerado acima é possível perceber que a coluna \"DT_CARGA\" apresenta apenas uma data. No momento foi levantada uma hipótese para justificar tal fato:\n",
    "- Esta coluna apresenta a data de realização da carga da base de dados para a utilização no projeto, o que justificaria a existência de apenas um valor na coluna e a existência da coluna de \"REQMATDATA\" que possui valores diferentes.\n",
    "\n",
    "Além disto, a coluna \"REQMATNUM\" apresenta apenas 70063 linhas, frente às 147006 linhas totais na tabela. Isto mostra que muitos valores se repetem. Acredita-se que a coluna em questão apresenta o ID da requisição de materiais, a princípio acreditou-se que este ID estaria repetido devido a duplicatas, no entanto ao analisar por exemplo as requisições com o ID '408618', percebe-se que os valores nas colunas \"ITREQMATQTD\", \"ITREQMATQTDCALC\", \"ITREQMATUNIDMEDCOD\", \"ITREQMATQTDATEND\" e \"ITREQMATQTDATENDCALC\" são diferentes em cada linha. Ainda não se fez possível entender completamente o porquê da questão, mas tendo em vista que os valores nas outras colunas são exatamente inguais em todas as linhas, acredita-se que:\n",
    "- A coluna 'REQMATNUM' apresenta o ID da requisiçã de materiais e que em uma única requisição podem ser solicitados diversos materiais em quantidades diferentes e com unidades de medida diversas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_wout_nan[database_wout_nan['REQMATNUM'] == 408618]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste ponto foram analisadas as colunas com valores numéricos citadas no texto acima, as quais são as únicas features que apresentam valores diferentes mesmo qeu possuam o mesmo ID de requisição. Assim, foram encintrados outliers quem devido à sua distância do comportamento padrão dos dados, foram removidos a fim de diminuir os ruídos da análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_wout_nan['ITREQMATQTDATENDCALC'].plot(kind='box', figsize=(7,3), vert=False)\n",
    "plt.show()\n",
    "database_wout_nan['ITREQMATQTDATEND'].plot(kind='box', figsize=(7,3), vert=False)\n",
    "plt.show()\n",
    "database_wout_nan['ITREQMATQTDCALC'].plot(kind='box', figsize=(7,3), vert=False)\n",
    "plt.show()\n",
    "database_wout_nan['ITREQMATQTD'].plot(kind='box', figsize=(7,3), vert=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if database_wout_nan['ITREQMATQTDCALC'].equals(database_wout_nan['ITREQMATQTD']):\n",
    "    print(\"Colunas iguais\")  \n",
    "else:\n",
    "    print(\"'ITREQMATQTDCALC' e 'ITREQMATQTD' são diferentes\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if database_wout_nan['ITREQMATQTDATEND'].equals(database_wout_nan['ITREQMATQTDATENDCALC']):\n",
    "    print(\"Colunas iguais\")  \n",
    "else:\n",
    "    print(\"'ITREQMATQTDATEND' e 'ITREQMATQTDATENDCALC' são diferentes\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_outliers(df_cleaned, threshold=3):\n",
    "    for column in df_cleaned.columns:\n",
    "        if np.issubdtype(df_cleaned[column].dtype, np.number):  \n",
    "            mean = np.mean(df_cleaned[column])\n",
    "            std_deviation = np.std(df_cleaned[column])\n",
    "            z_scores = (df_cleaned[column] - mean) / std_deviation\n",
    "            \n",
    "            outliers = abs(z_scores) > threshold\n",
    "            \n",
    "            df_cleaned = df_cleaned[~outliers]\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "database_wout_nan_outliers = remove_outliers(database_wout_nan, 3)     \n",
    "\n",
    "print(f'Shape com outliers: {database_wout_nan.shape}')\n",
    "print(f'Shape sem outliers: {database_wout_nan_outliers.shape}')  \n",
    "database_wout_nan_outliers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_wout_nan_outliers['REQMATSTAT'].value_counts().plot(kind='bar', figsize=(14,6), title='Distribuição de Status de Requisição de Material')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir dos gráficos apresentados a seguir seria interessante descobrir qual é a descrição de cada um dos 6 tipos de Status das requisições, dando mais enfoque àqueles de entendimento não tão claro, como: Pendente, Separada e Aberta. Isto pois seria interessante para as análises saber, por exemplo, qual a diferença de uma requisição Aberta e Pendente, dado que a partir do momento que uma requisição foi aberta já está pendente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_categories = ['Atendida Total', 'Atendida Parcial', 'Cancelada']\n",
    "data = database_wout_nan_outliers['REQMATSTAT'].apply(lambda x: x if x in top_categories else 'Outras')\n",
    "\n",
    "category_counts = data.value_counts(normalize=True) * 100  \n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "category_counts.plot(\n",
    "    kind='pie', \n",
    "    autopct='%1.1f%%',  \n",
    "    labels=category_counts.index, \n",
    "    colors=['skyblue', 'lightgreen', 'salmon', 'grey'], \n",
    "    startangle=90 ,\n",
    "    figsize=(12,12) \n",
    ")\n",
    "plt.ylabel('')  \n",
    "plt.title('Distribuição de Status de Requisição de Material')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_wout_nan_outliers['REQMATORIG'].value_counts().plot(kind='pie', figsize=(14,6), autopct='%1.1f%%', title='Distribuição de Origem de Requisição de Material')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_wout_nan.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = []\n",
    "\n",
    "for column in database_wout_nan:\n",
    "    if database_wout_nan[column].dtypes == object:\n",
    "        categorical_columns.append(column)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar a análise e geração de insights, abaixo é realizada a transformação de todas variaveis categóricas em variaveis numéricas através do Label Encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "for column in categorical_columns:\n",
    "    database_wout_nan_outliers[column] = label_encoder.fit_transform(database_wout_nan_outliers[column])\n",
    "\n",
    "database_wout_nan_outliers.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in database_wout_nan_outliers:\n",
    "    print(f\"Qtd. de NaN na coluna '{column}': {database_wout_nan_outliers[column].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_wout_nan_outliers.dropna(inplace=True)\n",
    "for column in database_wout_nan_outliers:\n",
    "    print(f\"Qtd. de NaN na coluna '{column}': {database_wout_nan_outliers[column].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_wout_nan_outliers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devido ao grande número de features na tabela, uma matriz de correlação dificilmente trará contribuições significativas à análise e que possam ser facilmente visualizadas, para provar este fato, tal matriz foi construída abaixo. \n",
    "\n",
    "E,bora possua um baixo nível de legibilidade, ainda assim a matriz traz algumas correlações que podem ser interessantes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = database_wout_nan_outliers.corr()\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "sns.heatmap(\n",
    "    correlation_matrix, \n",
    "    annot=True,        \n",
    "    cmap=\"coolwarm\",   \n",
    "    fmt=\".2f\",        \n",
    "    linewidths=0.5,  \n",
    "    square=True,      \n",
    "    cbar_kws={\"shrink\": 0.8}  \n",
    ")\n",
    "\n",
    "plt.title(\"Matriz de Correlação\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_database = scaler.fit_transform(database_wout_nan_outliers)\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X_database)\n",
    "\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.arange(1, len(explained_variance_ratio) + 1), explained_variance_ratio, marker='o', linestyle='--')\n",
    "plt.title('Explained Variance by Principal Components (Elbow Plot)')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.arange(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--')\n",
    "plt.axhline(y=0.90, color='r', linestyle='--', label='90% Variance Explained')\n",
    "plt.axhline(y=0.95, color='g', linestyle='--', label='95% Variance Explained')\n",
    "plt.title('Cumulative Explained Variance by Principal Components')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5)\n",
    "X_database_pca = pca.fit_transform(X_database)\n",
    "\n",
    "print(f'Variância explicada: {pca.explained_variance_ratio_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.scatter(X_database_pca[:, 0], X_database_pca[:, 1], alpha=0.7, c='blue', s=50)\n",
    "\n",
    "plt.title('PCA - First Two Principal Components')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_wout_nan_outliers.to_parquet('../../Datalake/req_materiais.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Considerações Finais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tabela não possibilitou a extração de muitos insights. Acredita-se que para uma melhor geração destes seja necessário um  dicionário que mostre o real significado de cada uma das colunas e possibilite entendê-las. Isto, pois muitas colunas apresentam nomes parecidos compostos por abreviações. Caso seja possível entender o que cada uma destas de fato significa, se fará possível olhar com mais intencionalidade para os dados apresentados por estas e, por conseguinte, gerar hipóteses efetivas e insights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
